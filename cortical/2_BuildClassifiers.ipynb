{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Classifier\n",
    "This notebook is dedicated to creating classifiers and run classification analyses of interest on neuroimaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insula_f3</th>\n",
       "      <th>LIPL_f3</th>\n",
       "      <th>MFG_f3</th>\n",
       "      <th>RIFG_f1</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>Left-Putamen</th>\n",
       "      <th>Right-Putamen</th>\n",
       "      <th>Left-Pallidum</th>\n",
       "      <th>Right-Pallidum</th>\n",
       "      <th>Left-Caudate</th>\n",
       "      <th>...</th>\n",
       "      <th>CBCL_internalizing_std</th>\n",
       "      <th>CBCL_externalizing_std</th>\n",
       "      <th>res_putamen</th>\n",
       "      <th>res_pall</th>\n",
       "      <th>res_caud</th>\n",
       "      <th>res_nacc</th>\n",
       "      <th>RSPS_f1</th>\n",
       "      <th>RMFG_f3</th>\n",
       "      <th>RIPL_F3</th>\n",
       "      <th>LOFC_f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>1.340000e+02</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.537452</td>\n",
       "      <td>2.770503</td>\n",
       "      <td>3.705037</td>\n",
       "      <td>2.666904</td>\n",
       "      <td>1.481158e+06</td>\n",
       "      <td>5298.224219</td>\n",
       "      <td>5337.238281</td>\n",
       "      <td>2014.197692</td>\n",
       "      <td>1927.068939</td>\n",
       "      <td>3834.638583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059289</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.036025</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>2.782600</td>\n",
       "      <td>2.606423</td>\n",
       "      <td>2.444999</td>\n",
       "      <td>1.537452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.245681</td>\n",
       "      <td>0.421733</td>\n",
       "      <td>0.440648</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>1.469610e+05</td>\n",
       "      <td>710.341560</td>\n",
       "      <td>634.935797</td>\n",
       "      <td>236.337617</td>\n",
       "      <td>249.043854</td>\n",
       "      <td>525.245559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005467</td>\n",
       "      <td>1.016694</td>\n",
       "      <td>0.681155</td>\n",
       "      <td>0.685004</td>\n",
       "      <td>0.724816</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.714813</td>\n",
       "      <td>0.449680</td>\n",
       "      <td>0.326264</td>\n",
       "      <td>0.245681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.016464</td>\n",
       "      <td>1.341230</td>\n",
       "      <td>2.764317</td>\n",
       "      <td>1.728269</td>\n",
       "      <td>1.142335e+06</td>\n",
       "      <td>3556.100000</td>\n",
       "      <td>3940.800000</td>\n",
       "      <td>1520.600000</td>\n",
       "      <td>1396.600000</td>\n",
       "      <td>2531.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.661238</td>\n",
       "      <td>-1.235337</td>\n",
       "      <td>-1.794073</td>\n",
       "      <td>-1.621015</td>\n",
       "      <td>-1.429075</td>\n",
       "      <td>-1.358056</td>\n",
       "      <td>1.381433</td>\n",
       "      <td>1.163695</td>\n",
       "      <td>1.214467</td>\n",
       "      <td>1.016464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.350520</td>\n",
       "      <td>2.491446</td>\n",
       "      <td>3.362829</td>\n",
       "      <td>2.355866</td>\n",
       "      <td>1.383378e+06</td>\n",
       "      <td>4844.575000</td>\n",
       "      <td>4912.500000</td>\n",
       "      <td>1835.600000</td>\n",
       "      <td>1753.500000</td>\n",
       "      <td>3528.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.803833</td>\n",
       "      <td>-1.023681</td>\n",
       "      <td>-0.448299</td>\n",
       "      <td>-0.479548</td>\n",
       "      <td>-0.557407</td>\n",
       "      <td>-0.500544</td>\n",
       "      <td>2.261016</td>\n",
       "      <td>2.311487</td>\n",
       "      <td>2.235609</td>\n",
       "      <td>1.350520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517579</td>\n",
       "      <td>2.799807</td>\n",
       "      <td>3.751267</td>\n",
       "      <td>2.615858</td>\n",
       "      <td>1.490017e+06</td>\n",
       "      <td>5286.850000</td>\n",
       "      <td>5295.400000</td>\n",
       "      <td>1995.650000</td>\n",
       "      <td>1907.400000</td>\n",
       "      <td>3812.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191401</td>\n",
       "      <td>-0.247607</td>\n",
       "      <td>0.035165</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>-0.008184</td>\n",
       "      <td>-0.054750</td>\n",
       "      <td>2.671038</td>\n",
       "      <td>2.605209</td>\n",
       "      <td>2.421827</td>\n",
       "      <td>1.517579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.716242</td>\n",
       "      <td>3.053427</td>\n",
       "      <td>4.037119</td>\n",
       "      <td>2.978805</td>\n",
       "      <td>1.581896e+06</td>\n",
       "      <td>5740.825000</td>\n",
       "      <td>5818.700000</td>\n",
       "      <td>2187.950000</td>\n",
       "      <td>2104.875000</td>\n",
       "      <td>4080.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>0.599020</td>\n",
       "      <td>0.452938</td>\n",
       "      <td>0.534231</td>\n",
       "      <td>0.496811</td>\n",
       "      <td>0.404827</td>\n",
       "      <td>3.267962</td>\n",
       "      <td>2.853014</td>\n",
       "      <td>2.665709</td>\n",
       "      <td>1.716242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.112390</td>\n",
       "      <td>4.005555</td>\n",
       "      <td>4.793296</td>\n",
       "      <td>4.017766</td>\n",
       "      <td>1.975068e+06</td>\n",
       "      <td>7658.500000</td>\n",
       "      <td>7436.300000</td>\n",
       "      <td>2712.700000</td>\n",
       "      <td>2570.800000</td>\n",
       "      <td>5572.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.421642</td>\n",
       "      <td>2.292272</td>\n",
       "      <td>1.446386</td>\n",
       "      <td>2.006917</td>\n",
       "      <td>1.638915</td>\n",
       "      <td>2.931471</td>\n",
       "      <td>4.721301</td>\n",
       "      <td>3.849567</td>\n",
       "      <td>3.416235</td>\n",
       "      <td>2.112390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Insula_f3     LIPL_f3      MFG_f3     RIFG_f1          eTIV  \\\n",
       "count  134.000000  134.000000  134.000000  134.000000  1.340000e+02   \n",
       "mean     1.537452    2.770503    3.705037    2.666904  1.481158e+06   \n",
       "std      0.245681    0.421733    0.440648    0.450980  1.469610e+05   \n",
       "min      1.016464    1.341230    2.764317    1.728269  1.142335e+06   \n",
       "25%      1.350520    2.491446    3.362829    2.355866  1.383378e+06   \n",
       "50%      1.517579    2.799807    3.751267    2.615858  1.490017e+06   \n",
       "75%      1.716242    3.053427    4.037119    2.978805  1.581896e+06   \n",
       "max      2.112390    4.005555    4.793296    4.017766  1.975068e+06   \n",
       "\n",
       "       Left-Putamen  Right-Putamen  Left-Pallidum  Right-Pallidum  \\\n",
       "count    128.000000     128.000000     130.000000      132.000000   \n",
       "mean    5298.224219    5337.238281    2014.197692     1927.068939   \n",
       "std      710.341560     634.935797     236.337617      249.043854   \n",
       "min     3556.100000    3940.800000    1520.600000     1396.600000   \n",
       "25%     4844.575000    4912.500000    1835.600000     1753.500000   \n",
       "50%     5286.850000    5295.400000    1995.650000     1907.400000   \n",
       "75%     5740.825000    5818.700000    2187.950000     2104.875000   \n",
       "max     7658.500000    7436.300000    2712.700000     2570.800000   \n",
       "\n",
       "       Left-Caudate     ...      CBCL_internalizing_std  \\\n",
       "count    127.000000     ...                  123.000000   \n",
       "mean    3834.638583     ...                   -0.059289   \n",
       "std      525.245559     ...                    1.005467   \n",
       "min     2531.100000     ...                   -1.661238   \n",
       "25%     3528.100000     ...                   -0.803833   \n",
       "50%     3812.500000     ...                   -0.191401   \n",
       "75%     4080.700000     ...                    0.543517   \n",
       "max     5572.700000     ...                    2.421642   \n",
       "\n",
       "       CBCL_externalizing_std  res_putamen    res_pall    res_caud  \\\n",
       "count              123.000000   118.000000  118.000000  118.000000   \n",
       "mean                -0.034229     0.022736    0.036025    0.005033   \n",
       "std                  1.016694     0.681155    0.685004    0.724816   \n",
       "min                 -1.235337    -1.794073   -1.621015   -1.429075   \n",
       "25%                 -1.023681    -0.448299   -0.479548   -0.557407   \n",
       "50%                 -0.247607     0.035165    0.080088   -0.008184   \n",
       "75%                  0.599020     0.452938    0.534231    0.496811   \n",
       "max                  2.292272     1.446386    2.006917    1.638915   \n",
       "\n",
       "         res_nacc     RSPS_f1     RMFG_f3     RIPL_F3     LOFC_f3  \n",
       "count  118.000000  134.000000  134.000000  134.000000  134.000000  \n",
       "mean     0.019501    2.782600    2.606423    2.444999    1.537452  \n",
       "std      0.753716    0.714813    0.449680    0.326264    0.245681  \n",
       "min     -1.358056    1.381433    1.163695    1.214467    1.016464  \n",
       "25%     -0.500544    2.261016    2.311487    2.235609    1.350520  \n",
       "50%     -0.054750    2.671038    2.605209    2.421827    1.517579  \n",
       "75%      0.404827    3.267962    2.853014    2.665709    1.716242  \n",
       "max      2.931471    4.721301    3.849567    3.416235    2.112390  \n",
       "\n",
       "[8 rows x 75 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "# Study specific variables\n",
    "study_home = '/home/camachocm2/Analysis/aggregate_anats'\n",
    "preproc_dir = study_home + '/proc/subj_data'\n",
    "standard_mask = preproc_dir + '/sample_template/lcbd_template_mask.nii.gz'\n",
    "template = preproc_dir + '/sample_template/lcbd_template0.nii.gz'\n",
    "sub_data_file = study_home + '/results/feature_all_data_20190320.csv'\n",
    "#brain_feature_data = study_home + '/proc/group_data/mvpa/data_merged_smooth.nii.gz'\n",
    "#brain_feature_data = study_home + '/proc/group_data/mvpa/fullCT_resids.nii.gz'\n",
    "brain_feature_data = study_home + '/proc/group_data/mvpa/resids_CT_withage.nii.gz'\n",
    "output_dir = study_home + '/proc/group_data/mvpa'\n",
    "\n",
    "subject_info = read_csv(sub_data_file, index_col=0)\n",
    "subject_info.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create feature set and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    134.000000\n",
       "mean      -0.039009\n",
       "std        0.943274\n",
       "min       -1.962494\n",
       "25%       -0.666022\n",
       "50%       -0.081934\n",
       "75%        0.680102\n",
       "max        1.926131\n",
       "Name: Factor1, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine which analysis to run\n",
    "analysis = 'Factor1'\n",
    "import numpy as np\n",
    "\n",
    "if analysis == 'Factor1':\n",
    "    mask = subject_info['Factor1'] !=np.nan\n",
    "    labels = subject_info['Factor1']\n",
    "    type_svm = 'nonbinary'\n",
    "elif analysis == 'age':\n",
    "    mask = subject_info['Age_yrs'] >0\n",
    "    labels = subject_info['Age_yrs']\n",
    "    type_svm = 'nonbinary'\n",
    "elif analysis == 'extern':\n",
    "    mask = subject_info['CBCL_externalizing']>0\n",
    "    labels = subject_info['CBCL_externalizing']\n",
    "    type_svm = 'nonbinary'\n",
    "elif analysis=='age_factor1':\n",
    "    mask = subject_info['Factor1'] !=np.nan\n",
    "\n",
    "results_file = open(output_dir + '/results_' + analysis + '_withagereal.txt','w')\n",
    "out_file = output_dir + '/svrweights_' + analysis + '_withagereal.nii.gz'\n",
    "labels[mask].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification\n",
    "\n",
    "The below cells perform categorical classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_svm == 'binary':\n",
    "    # Perform the support vector classification\n",
    "    from nilearn.input_data import NiftiMasker\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Set up the support vector classifier\n",
    "    svc = SVC(kernel='linear')\n",
    "    masker = NiftiMasker(mask_img=gm_mask,standardize=True, \n",
    "                         memory='nilearn_cache', memory_level=1)\n",
    "    \n",
    "    # Select the features contributing to the model\n",
    "    feature_selection = SelectPercentile(f_classif, percentile=5) #0.05/228453 voxels\n",
    "    fs_svc = Pipeline([('feat_select', feature_selection), ('svc', svc)])\n",
    "\n",
    "    # Run the classifier\n",
    "    X = masker.fit_transform(brain_feature_data)\n",
    "    X = X[mask]\n",
    "    maskedlabels=labels[mask]\n",
    "    fs_svc.fit(X, maskedlabels)\n",
    "    \n",
    "    # Obtain prediction values via cross validation\n",
    "    from sklearn.model_selection import cross_validate, LeaveOneGroupOut, cross_val_predict\n",
    "\n",
    "    loso = LeaveOneGroupOut()\n",
    "    cv_scores = cross_validate(fs_svc, X, y=maskedlabels, n_jobs=10, return_train_score=True,\n",
    "                               groups=conditions['subject'][mask], cv=loso, scoring='accuracy')\n",
    "    y_pred = cross_val_predict(fs_svc, X, y=maskedlabels, n_jobs=10,\n",
    "                               groups=conditions['subject'][mask], cv=loso)\n",
    "    \n",
    "    ## Save the SVM weights to a nifti\n",
    "    coef = svc.coef_\n",
    "    coef = feature_selection.inverse_transform(coef)\n",
    "    weight_img = masker.inverse_transform(coef)\n",
    "    weight_img.to_filename(output_dir + '/svmweights_'+ analysis +'.nii.gz')\n",
    "    \n",
    "    ## Calculate performance metrics\n",
    "    from sklearn.metrics import recall_score, precision_score\n",
    "    \n",
    "    classification_accuracy = cv_scores['test_score'].mean()\n",
    "    chance = 1. / len(labels.unique())\n",
    "    print(\"Classification accuracy: %.4f / Chance level: %f\" % \n",
    "          (classification_accuracy, chance))\n",
    "    \n",
    "    for label in maskedlabels.unique():\n",
    "        sensitivity = recall_score(maskedlabels,y_pred,labels=[label],average='weighted')\n",
    "        precision = precision_score(maskedlabels,y_pred,labels=[label],average='weighted')\n",
    "        \n",
    "        results_file.write(\"%s: classification accuracy: %.4f \\n chance level: %f \\n sensitivity: %f \\n precision: %f \\n\" % \n",
    "        (label, classification_accuracy, chance, sensitivity, precision))\n",
    "    \n",
    "    # compute and display a confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from numpy import set_printoptions\n",
    "    import itertools\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cnf_matrix = confusion_matrix(maskedlabels, y_pred)\n",
    "    set_printoptions(precision=2)\n",
    "    classes = maskedlabels.unique()\n",
    "\n",
    "    def plot_confusion_matrix(cm, classes):\n",
    "        from numpy import arange\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.colorbar()\n",
    "        tick_marks = arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45, size=16)\n",
    "        plt.yticks(tick_marks, classes, size=16)\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j],  'd'),\n",
    "                     horizontalalignment='center',\n",
    "                     color='white' if cm[i, j] > thresh else 'black', size=16)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label', size=16)\n",
    "        plt.xlabel('Predicted label', size=16)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes)\n",
    "    plt.savefig(output_dir + '/confusion_matrix_' + analysis + '.svg', transparent=True)\n",
    "    plt.close()\n",
    "    \n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform permutation testing to get a p-value for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "N.B.: in order to use the below function (permutation_test_score) for this particular analysis, \n",
    "I added the following code to the _shuffle function (starts on line 966 of sklearn/model_selection/_validation.py) code:\n",
    "\n",
    "     elif permute_groups==True:\n",
    "        indices = np.arange(len(groups))\n",
    "        indices = random_state.permutation(indices)\n",
    "\n",
    "and I added an argument to the permutation_test_score function (permute_groups=True) that is passed to the _shuffle function. \n",
    "This enables groups to be used for cross validation, but ignores groups for permutation. This is useful if you have multiple\n",
    "features per subject with the same label and you are using grouping to denote a whole subject for LOSO cross validation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "\n",
    "results_file = open(output_dir + '/permut_results_' + analysis + '_final.txt','w')\n",
    "\n",
    "if type_svm == 'binary':\n",
    "    # Perform permutation testing to get a p-value\n",
    "    score, permutation_scores, pvalue = permutation_test_score(fs_svc, X, maskedlabels, scoring='accuracy', \n",
    "                                                               cv=loso, n_permutations=500, n_jobs=10, \n",
    "                                                               groups=conditions['subject'][mask], permute_groups=True)\n",
    "    savetxt(output_dir + '/permutation_scores_' + analysis + '.txt', permutation_scores)\n",
    "\n",
    "    print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
    "    # Save a figure of the permutation scores\n",
    "    plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "             edgecolor='black')\n",
    "    ylim = plt.ylim()\n",
    "    plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "             label='Classification Score (pvalue %f)' % pvalue)\n",
    "    plt.plot(2 * [1. / len(labels.unique())], ylim, '--k', linewidth=3, label='Luck')\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.savefig(output_dir + '/permutation_plot_' + analysis + '.svg', transparent=True)\n",
    "    plt.close()\n",
    "    \n",
    "    # save final pval/classifier score\n",
    "    results_file.write(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "\n",
    "The below cells performs continuous classification (i.e. predict a continuous variable) based on age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: -0.2119 / p-value: 0.013982 / MSE: 74.257216 // Spearman: -0.054901 / p-value: 0.528665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if type_svm == 'nonbinary':\n",
    "    # Perform the support vector classification\n",
    "    from nilearn.input_data import NiftiMasker\n",
    "    from sklearn.feature_selection import f_regression, SelectPercentile\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Set up the regression\n",
    "    svr = SVR(kernel='linear', C=1)\n",
    "    masker = NiftiMasker(mask_img=standard_mask,standardize=True, \n",
    "                         memory='nilearn_cache', memory_level=1)\n",
    "    \n",
    "    feature_selection = SelectPercentile(f_regression, percentile=5)\n",
    "    fs_svr = Pipeline([('feat_select', feature_selection), ('svr', svr)])\n",
    "    \n",
    "    # Run the regression\n",
    "    X = masker.fit_transform(brain_feature_data)\n",
    "    X = X[mask]\n",
    "    maskedlabels=labels[mask]\n",
    "    fs_svr.fit(X, maskedlabels)\n",
    "        \n",
    "    from sklearn.model_selection import cross_val_predict, LeaveOneGroupOut\n",
    "\n",
    "    loso = LeaveOneGroupOut()\n",
    "    y_pred = cross_val_predict(fs_svr, X, y=maskedlabels, n_jobs=20,\n",
    "                               groups=subject_info['freesurferID'][mask],cv=loso)\n",
    "    # save weights\n",
    "    coef = svr.coef_\n",
    "    coef = feature_selection.inverse_transform(coef)\n",
    "    coef_image = masker.inverse_transform(coef)\n",
    "    coef_image.to_filename(out_file)\n",
    "    \n",
    "    results_df = subject_info[mask]\n",
    "    results_df['pred' + analysis] = Series(y_pred, index=results_df.index)\n",
    "    results_df.head()\n",
    "    \n",
    "    \n",
    "    from scipy.stats import linregress\n",
    "    slope, intercept, r_val, p_val, stderr = linregress(maskedlabels, y_pred) \n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(maskedlabels, y_pred)\n",
    "    \n",
    "    from scipy.stats import spearmanr\n",
    "    spear_r, spear_p = spearmanr(maskedlabels, y_pred)\n",
    "\n",
    "    print(\"prediction accuracy: %.4f / p-value: %f / MSE: %f // Spearman: %f / p-value: %f\" % (r_val, p_val, mse, spear_r, spear_p))\n",
    "\n",
    "    # plot the predicted versus actual values\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.scatter(maskedlabels, y_pred, color='b')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.savefig(output_dir + '/scatter_pred_actual_mean_' + analysis + '_final.svg', transparent=True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    results_file.write(\"MEAN prediction accuracy r-value: %.4f / p-value: %f / MSE: %f // Spearman: %f / p-value: %f \\n\" % (r_val, p_val, mse, spear_r, spear_p))\n",
    "    results_file.write('predicted: ' + str(y_pred) + '\\n')\n",
    "    results_file.write('actual: ' + str(maskedlabels) + '\\n')\n",
    "\n",
    "    results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform permutation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_svm == 'nonbinary':\n",
    "    ## Perform permutation testing to get a p-value for MSE\n",
    "    score, permutation_scores, pvalue = permutation_test_score(fs_svr, X, maskedlabels, scoring='neg_mean_squared_error', \n",
    "                                                               cv=loso, n_permutations=1000, n_jobs=20, \n",
    "                                                               groups=subject_info['freesurferID'][mask])\n",
    "    savetxt(output_dir + '/permutation_scores_mse_' + analysis + '.txt', permutation_scores)\n",
    "\n",
    "    # Save a figure of the permutation scores\n",
    "    plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "             edgecolor='black')\n",
    "    ylim = plt.ylim()\n",
    "    plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "             label='Mean Squared Error (pvalue %f)' % pvalue)\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.savefig(output_dir + '/permutation_plot_mse_' + analysis + '.svg', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    # save final pval/classifier score\n",
    "    results_file.write('MSE score %s (pvalue : %s) \\n' % (score, pvalue))\n",
    "    \n",
    "    ## Perform permutation testing to get a p-value for r-squared\n",
    "    score, permutation_scores, pvalue = permutation_test_score(fs_svr, X, maskedlabels, scoring='r2', \n",
    "                                                               cv=loso, n_permutations=1000, n_jobs=20, \n",
    "                                                               groups=subject_info['freesurferID'][mask])\n",
    "    savetxt(output_dir + '/permutation_scores_r2_' + analysis + '.txt', permutation_scores)\n",
    "\n",
    "    # Save a figure of the permutation scores\n",
    "    plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "             edgecolor='black')\n",
    "    ylim = plt.ylim()\n",
    "    plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "             label='R-squared (pvalue %f)' % pvalue)\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.savefig(output_dir + '/permutation_plot_r2_' + analysis + '.svg', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    # save final pval/classifier score\n",
    "    results_file.write('R square: %s (pvalue : %s) \\n' % (score, pvalue))\n",
    "    results_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from numpy import mean, std, loadtxt\n",
    "files = glob('/home/camachocm2/Analysis/KidVid_MVPA/analysis/classifier/final_SVM_linear_5percent/permutation_scores_*.txt')\n",
    "for file in files:\n",
    "    analysis = file[103:-4]\n",
    "    scores = loadtxt(file)\n",
    "    print(analysis + ' average = ' + str(mean(scores)) + ', SD = ' + str(std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
