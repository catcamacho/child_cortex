{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the modules\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode, JoinNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, FreeSurferSource\n",
    "from nipype.interfaces.fsl import FAST, Reorient2Std, Merge, MeanImage\n",
    "from nipype.interfaces.freesurfer import FSCommand, MRIConvert, Binarize\n",
    "from nipype.interfaces.ants import RegistrationSynQuick, ApplyTransforms, CorticalThickness\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "from glob import glob\n",
    "\n",
    "# FSL setup- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "#freesurfer setup\n",
    "fs_dir = '/moochie/Cat/Aggregate_anats/subjects_dir'\n",
    "FSCommand.set_default_subjects_dir(fs_dir)\n",
    "\n",
    "# Study specific variables\n",
    "analysis_home = '/home/camachocm2/Analysis/aggregate_anats'\n",
    "\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "proc_dir = analysis_home + '/proc/subj_data'\n",
    "group_dir = analysis_home + '/proc/group_data'\n",
    "\n",
    "subject_info = read_csv(analysis_home + '/misc/subjs.csv', index_col=0)\n",
    "all_subjects = subject_info['fsID'].tolist()\n",
    "\n",
    "template_subjects_list = analysis_home + '/misc/template_subs.txt'\n",
    "template_subjects = open(template_subjects_list).read().splitlines()\n",
    "tissue_subjects = ['236','2020','2007','105','109','112','113','125','223','1010']\n",
    "\n",
    "#set up datasink\n",
    "substitutions = [('_subject_id_','')]\n",
    "datasink = Node(DataSink(substitutions=substitutions,\n",
    "                         base_directory = proc_dir),\n",
    "                name = 'datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Template Brain Creation\n",
    "This section creates a template representative of the sample based on a predetermined list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Set up nodes for file handling #####\n",
    "\n",
    "template_source = MapNode(FreeSurferSource(subjects_dir = fs_dir), \n",
    "                          name = 'template_source', \n",
    "                          iterfield = ['subject_id'])\n",
    "template_source.inputs.subject_id = template_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation functions #########\n",
    "def make3DTemplate(subject_T1s, num_proc, output_prefix):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from os.path import abspath, split\n",
    "    from os import getcwd\n",
    "    from shutil import copyfile\n",
    "    from glob import glob\n",
    "    from subprocess import check_call\n",
    "\n",
    "    curr_dir = getcwd()\n",
    "\n",
    "    #copy T1s into current directory\n",
    "    for T in range(0,len(subject_T1s)):\n",
    "        [dirname,filename] = split(subject_T1s[T])\n",
    "        copyfile(subject_T1s[T],curr_dir + '/S' + str(T)+'_'+filename)\n",
    "\n",
    "    # -c flag is control for local computing (2= use localhost; required for -j flag)\n",
    "    # -j flag is for number of processors allowed\n",
    "    check_call(['antsMultivariateTemplateConstruction2.sh', '–d','3','–o', output_prefix,'–r','1','–c','2','–j', str(num_proc), '*.nii.gz'])\n",
    "    \n",
    "    sample_template = abspath(output_prefix + 'template0.nii.gz')\n",
    "    \n",
    "    return(sample_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation nodes #########\n",
    "\n",
    "#convert freesurfer brainmask files to .nii\n",
    "convertT1 = Node(MRIConvert(out_file='T1.nii.gz',\n",
    "                            out_type='niigz'), \n",
    "                 name='convertT1')\n",
    "\n",
    "#reorient files to standard space\n",
    "reorientT1 = MapNode(Reorient2Std(),\n",
    "                     name = 'reorientT1',\n",
    "                     iterfield = ['in_file'])\n",
    "\n",
    "#pass files into template function (normalized, pre-skull-stripping)\n",
    "makeTemplate = Node(Function(input_names=['subject_T1s','num_proc','output_prefix'],\n",
    "                             output_names=['sample_template'],\n",
    "                             function=make3DTemplate),\n",
    "                    name='makeTemplate')\n",
    "makeTemplate.inputs.num_proc=4 \n",
    "makeTemplate.inputs.output_prefix='Child_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Template creation workflow #########\n",
    "template_flow = Workflow(name = 'template_flow')\n",
    "template_flow.connect([(template_source, convertT1, [('T1','in_file')]),\n",
    "                       (convertT1, reorientT1, [('out_file', 'in_file')]),\n",
    "                       (reorientT1, makeTemplate, [('out_file', 'subject_T1s')]),\n",
    "                       (reorientT1, datasink, [('out_file','proc_T1s')]),\n",
    "                       (makeTemplate, datasink, [('sample_template', 'sample_template')])\n",
    "                      ])\n",
    "\n",
    "template_flow.base_dir = workflow_dir\n",
    "template_flow.write_graph(graph2use = 'flat')\n",
    "template_flow.run(plugin='MultiProc',plugin_args={'memory_gb':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tissue Segmentation\n",
    "This next section creates the 4 tissue segmentations plus a brainmask for cortical thickness estimation tissue priors:\n",
    "1. CSF \n",
    "2. cortical gray matter \n",
    "3. Subcortical gray matter\n",
    "4. White matter   \n",
    "5. Brainstem\n",
    "6. Cerebellum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data handling nodes\n",
    "\n",
    "# subject handling node\n",
    "infosource = Node(IdentityInterface(fields=['subject_id']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subject_id', template_subjects)]\n",
    "\n",
    "\n",
    "#pull freesurfer data\n",
    "tissue_source = Node(FreeSurferSource(subjects_dir = fs_dir),\n",
    "                     name = 'tissue_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Tissue labeling functions\n",
    "\n",
    "def relabel_fast(fast_tissue_list):\n",
    "    from nipype import config, logging\n",
    "    from os.path import split\n",
    "    from os import rename\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    tissue_list = sorted(fast_tissue_list)\n",
    "    csf = tissue_list[0]\n",
    "    wm = tissue_list[2]\n",
    "    [wd, csf_file] = split(csf)\n",
    "    [wd, wm_file] = split(wm)\n",
    "    rename(csf, wd + 'csf.nii.gz')\n",
    "    rename(wm, wd + 'wm.nii.gz')\n",
    "    wm_csf = [wd + 'csf.nii.gz', wd + 'wm.nii.gz']\n",
    "    return(wm_csf)\n",
    "\n",
    "# Create subcortical and cortical gray matter masks <-- custom function. inputs: fs aseg + tissue class files\n",
    "def aseg_to_tissuemaps(aseg):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import zeros_like\n",
    "    from os.path import abspath\n",
    "    aseg_nifti = load(aseg)\n",
    "    aseg_data = aseg_nifti.get_data()\n",
    "    cortical_labels = [3, 42]\n",
    "    subcortical_labels =[10, 11, 12, 13, 17, 18, 26, 49, 50, 51, 52, 53, 54, 58, 28, 60]\n",
    "    brainstem_labels = [16]\n",
    "    cerebellum_labels = [6, 7, 8, 45, 46, 47]\n",
    "\n",
    "    #creating array of zeroes that replaces 0's with 1's when matches values of subcortical_labels\n",
    "    cortical_data = zeros_like(aseg_data)\n",
    "    for x in cortical_labels:\n",
    "        cortical_data[aseg_data == x] = 1\n",
    "    cortical_nifti = Nifti1Image(cortical_data, aseg_nifti.affine)\n",
    "    \n",
    "    subcort_data = zeros_like(aseg_data) \n",
    "    for x in subcortical_labels:\n",
    "        subcort_data[aseg_data == x] = 1\n",
    "    subcort_nifti = Nifti1Image(subcort_data, aseg_nifti.affine)\n",
    "    \n",
    "    bs_data = zeros_like(aseg_data) \n",
    "    for x in brainstem_labels:\n",
    "        bs_data[aseg_data == x] = 1\n",
    "    bs_nifti = Nifti1Image(bs_data, aseg_nifti.affine)\n",
    "    \n",
    "    cb_data = zeros_like(aseg_data) \n",
    "    for x in cerebellum_labels:\n",
    "        cb_data[aseg_data == x] = 1\n",
    "    cb_nifti = Nifti1Image(cb_data, aseg_nifti.affine)\n",
    "    \n",
    "    save(subcort_nifti, 'subcortical_gm.nii.gz')\n",
    "    save(cortical_nifti, 'cortical_gm.nii.gz')\n",
    "    save(bs_nifti, 'brainstem.nii.gz')\n",
    "    save(cb_nifti, 'cerebellum.nii.gz')\n",
    "    subcort_file = abspath('subcortical_gm.nii.gz')\n",
    "    cortical_file = abspath('cortical_gm.nii.gz')\n",
    "    brainstem_file = abspath('brainstem.nii.gz')\n",
    "    cerebellum_file = abspath('cerebellum.nii.gz')\n",
    "    gm_list = [subcort_file, cortical_file, brainstem_file, cerebellum_file]\n",
    "    return(gm_list)\n",
    "\n",
    "def combine_seg(file_list_1, file_list_2):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import zeros_like\n",
    "    from os.path import abspath\n",
    "\n",
    "    in_files = file_list_1 + file_list_2\n",
    "\n",
    "    for tissue in in_files:\n",
    "        if 'segmentcsf' in tissue:\n",
    "            csf_file = tissue\n",
    "            csf_nifti = load(csf_file)\n",
    "            csf_data = csf_nifti.get_data()\n",
    "        elif 'subcortical' in tissue:\n",
    "            subcortical_file = tissue\n",
    "            sc_nifti = load(subcortical_file)\n",
    "            sc_data = sc_nifti.get_data()\n",
    "        elif 'cortical' in tissue:\n",
    "            cortex_file = tissue\n",
    "            cort_nifti = load(cortex_file)\n",
    "            cort_data = cort_nifti.get_data()\n",
    "        elif 'segmentwm' in tissue:\n",
    "            wm_file = tissue\n",
    "            wm_nifti = load(wm_file)\n",
    "            wm_data = wm_nifti.get_data()\n",
    "        elif 'brainstem' in tissue:\n",
    "            brainstem_file = tissue\n",
    "            bs_nifti = load(brainstem_file)\n",
    "            bs_data = bs_nifti.get_data()\n",
    "        elif 'cerebellum' in tissue:\n",
    "            cerebellum_file = tissue\n",
    "            cb_nifti = load(cerebellum_file)\n",
    "            cb_data = cb_nifti.get_data()\n",
    "\n",
    "    combined_labels_data = zeros_like(csf_data)\n",
    "\n",
    "    # these are done in a deliberate order, later tissues overwrite previous ones\n",
    "    combined_labels_data[csf_data>0] = 1\n",
    "    combined_labels_data[wm_data>0] = 4\n",
    "    combined_labels_data[bs_data>0] = 5\n",
    "    combined_labels_data[sc_data>0] = 3\n",
    "    combined_labels_data[cb_data>0] = 6\n",
    "    combined_labels_data[cort_data>0] = 2\n",
    "\n",
    "    combined_labels_nii = Nifti1Image(combined_labels_data, csf_nifti.affine)\n",
    "    combined_labels_file = save(combined_labels_nii, 'combined_tissues.nii.gz')\n",
    "    tissue_map = abspath('combined_tissues.nii.gz')\n",
    "    \n",
    "    return(tissue_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## tissue labeling nodes\n",
    "\n",
    "#convert freesurfer brainmask files to .nii\n",
    "convert_to_nii = Node(MRIConvert(out_file='brain.nii.gz',\n",
    "                                 out_type='niigz'), \n",
    "                      name='convert_to_nii')\n",
    "\n",
    "#reorient brainmask file to standard\n",
    "reorient_to_std = Node(Reorient2Std(),\n",
    "                       name = 'reorient_to_std')\n",
    "\n",
    "#convert freesurfer T1 file to .nii\n",
    "convert_T1 = Node(MRIConvert(out_file='brain.nii.gz',\n",
    "                             out_type='niigz'),\n",
    "                  name='convert_T1')\n",
    "\n",
    "#reorient brainmask file to standard\n",
    "reorient_T1 = Node(Reorient2Std(),\n",
    "                   name = 'reorient_T1')\n",
    "\n",
    "#binarize the freesurfer brainmask so it's a true mask\n",
    "binarize_bm = Node(Binarize(min=20, dilate=1, erode=1), \n",
    "                   name='binarize_bm')\n",
    "\n",
    "# Reorient aseg to standard\n",
    "reorient_aseg = Node(Reorient2Std(),\n",
    "                     name = 'reorient_aseg')\n",
    "\n",
    "#T1 gets run through segmentation (2) ---> results in segmentation into 3 tissue classes (wm, gm, csf)\n",
    "segment = Node(FAST(number_classes = 3, \n",
    "                    segments=True, \n",
    "                    no_bias=True), \n",
    "               name = 'segment')\n",
    "\n",
    "# Convert freesurfer aseg to nii\n",
    "convert_aseg = Node(MRIConvert(out_file='aseg.nii.gz',\n",
    "                               out_type='niigz'), \n",
    "                    name='convert_aseg')\n",
    "\n",
    "# Split aseg into to types of gray matter\n",
    "aseg_to_gm = Node(Function(input_names=['aseg'],\n",
    "                           output_names=['gm_list'],\n",
    "                           function=aseg_to_tissuemaps),\n",
    "                  name='aseg_to_gm')\n",
    "\n",
    "# Relabel the FAST segmentation \n",
    "relabel_fast_seg = Node(Function(input_names=['fast_tissue_list'],\n",
    "                                 output_names=['wm_csf'],\n",
    "                                 function=relabel_fast),\n",
    "                        name='relabel_fast_seg')\n",
    "\n",
    "#combine tissue segmentation to 1 volume for easier editing of tissue priors\n",
    "combine_labels = Node(Function(input_names=['file_list_1', 'file_list_2'], \n",
    "                               output_names=['tissue_map'], \n",
    "                               function=combine_seg),\n",
    "                      name='combine_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Tissue segmentation workflow #########\n",
    "segment_flow = Workflow(name = 'segment_flow')\n",
    "segment_flow.connect([(infosource, tissue_source, [('subject_id','subject_id')]),\n",
    "                      (tissue_source, convert_to_nii, [('brainmask','in_file')]),\n",
    "                      (convert_to_nii, reorient_to_std, [('out_file', 'in_file')]),\n",
    "                      (reorient_to_std, segment, [('out_file', 'in_files')]),\n",
    "                      (segment, relabel_fast_seg, [('tissue_class_files', 'fast_tissue_list')]),\n",
    "                      (tissue_source, convert_aseg, [('aseg','in_file')]),\n",
    "                      (convert_aseg, reorient_aseg, [('out_file', 'in_file')]),\n",
    "                      (reorient_aseg, aseg_to_gm, [('out_file', 'aseg')]),\n",
    "                      (aseg_to_gm, combine_labels, [('gm_list','file_list_1')]),\n",
    "                      (relabel_fast_seg, combine_labels, [('wm_csf','file_list_2')]),\n",
    "                      (tissue_source, convert_T1, [('T1','in_file')]),\n",
    "                      (convert_T1, reorient_T1, [('out_file','in_file')]),\n",
    "                      (reorient_to_std, binarize_bm, [('out_file','in_file')]),\n",
    "                      \n",
    "                      (binarize_bm, datasink, [('binary_file','brain_mask')]),\n",
    "                      (reorient_T1, datasink, [('out_file','subject_T1')]),\n",
    "                      (combine_labels, datasink, [('tissue_map','combined_labels')])\n",
    "                     ])\n",
    "\n",
    "segment_flow.base_dir = workflow_dir\n",
    "segment_flow.write_graph(graph2use = 'flat')\n",
    "segment_flow.run('MultiProc', plugin_args={'n_procs': 1, 'memory_gb':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tissue Priors\n",
    "This section creates the tissue priors (after manual editing the outputs from the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data handling nodes\n",
    "template_brain = proc_dir + '/sample_template/lcbd_template0.nii.gz'\n",
    "priors_source_files = {'tissue_map': proc_dir + '/combined_labels/{subject_id}/combined_tissues.nii.gz',\n",
    "                       'T1': proc_dir + '/subject_T1/{subject_id}/brain_reoriented.nii.gz', \n",
    "                       'brainmask': proc_dir + '/brain_mask/{subject_id}/brainmask_reoriented_thresh.nii.gz'}\n",
    "priors_files = Node(SelectFiles(priors_source_files), name='template_files')\n",
    "priors_files.iterables = [('subject_id',tissue_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tissue_labels(combined_labels):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import zeros_like\n",
    "    from os.path import abspath\n",
    "    \n",
    "    labeled_nifti = load(combined_labels)\n",
    "    labeled_data = labeled_nifti.get_data()\n",
    "    \n",
    "    segment1_data = zeros_like(labeled_nifti.get_data())\n",
    "    segment1_data[labeled_data==1] = 1\n",
    "    segment1_img = Nifti1Image(segment1_data,labeled_nifti.affine)\n",
    "    save(segment1_img, 'tissue_class1.nii.gz')\n",
    "    segment1 = abspath('tissue_class1.nii.gz')\n",
    "    \n",
    "    segment2_data = zeros_like(labeled_nifti.get_data())\n",
    "    segment2_data[labeled_data==2] = 1    \n",
    "    segment2_img = Nifti1Image(segment2_data, header=labeled_nifti.header, affine=labeled_nifti.affine)\n",
    "    save(segment2_img, 'tissue_class2.nii.gz')\n",
    "    segment2 = abspath('tissue_class2.nii.gz')\n",
    "    \n",
    "    segment3_data = zeros_like(labeled_nifti.get_data())\n",
    "    segment3_data[labeled_data==3] = 1\n",
    "    segment3_img = Nifti1Image(segment3_data, header=labeled_nifti.header, affine=labeled_nifti.affine)\n",
    "    save(segment3_img, 'tissue_class3.nii.gz')\n",
    "    segment3 = abspath('tissue_class3.nii.gz')\n",
    "    \n",
    "    segment4_data = zeros_like(labeled_nifti.get_data())\n",
    "    segment4_data[labeled_data==4] = 1\n",
    "    segment4_img = Nifti1Image(segment4_data, header=labeled_nifti.header, affine=labeled_nifti.affine)\n",
    "    save(segment4_img, 'tissue_class4.nii.gz')\n",
    "    segment4 = abspath('tissue_class4.nii.gz')\n",
    "    \n",
    "    segment5_data = zeros_like(labeled_nifti.get_data())\n",
    "    segment5_data[labeled_data==5] = 1\n",
    "    segment5_img = Nifti1Image(segment5_data, header=labeled_nifti.header, affine=labeled_nifti.affine)\n",
    "    save(segment5_img, 'tissue_class5.nii.gz')\n",
    "    segment5 = abspath('tissue_class5.nii.gz')\n",
    "    \n",
    "    segment6_data = zeros_like(labeled_nifti.get_data())\n",
    "    segment6_data[labeled_data==6] = 1\n",
    "    segment6_img = Nifti1Image(segment6_data, header=labeled_nifti.header, affine=labeled_nifti.affine)\n",
    "    save(segment6_img, 'tissue_class6.nii.gz')\n",
    "    segment6 = abspath('tissue_class6.nii.gz')\n",
    "    \n",
    "    tissues = [segment1,segment2,segment3,segment4,segment5,segment6]\n",
    "    return(tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tissue priors nodes\n",
    "split_tissues = Node(Function(input_names=['combined_labels'],\n",
    "                              output_names=['tissues'],\n",
    "                              function=split_tissue_labels), \n",
    "                     name='split_tissues')\n",
    "# register to template\n",
    "reg_to_template = Node(RegistrationSynQuick(fixed_image=template_brain),\n",
    "                       name = 'reg_to_template')\n",
    "\n",
    "# apply the transform to the tissue maps\n",
    "applyxform = MapNode(ApplyTransforms(reference_image=template_brain), name = 'applyxform', iterfield=['input_image'])\n",
    "\n",
    "# apply the transform to the tissue maps\n",
    "applyxformBM = Node(ApplyTransforms(reference_image=template_brain), name = 'applyxformBM')\n",
    "\n",
    "# merge brainmasks together\n",
    "mergeBM = JoinNode(Merge(dimension='t'), name='mergeBM', joinsource='priors_files',joinfield='in_files')\n",
    "\n",
    "# average brain masks to make brain prior\n",
    "avg_brainmasks = Node(MeanImage(dimension='T',output_datatype='double',out_file='brain_prior.nii.gz'), \n",
    "                      name='avg_brainmasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissuepriors_flow = Workflow(name = 'tissuepriors_flow')\n",
    "tissuepriors_flow.connect([(priors_files, reg_to_template, [('T1', 'moving_image')]),\n",
    "                           (reg_to_template, applyxform, [('out_matrix','transforms')]),\n",
    "                           (reg_to_template, applyxformBM, [('out_matrix','transforms')]),\n",
    "                           (priors_files, split_tissues, [('tissue_map','combined_labels')]), \n",
    "                           (split_tissues, applyxform, [('tissues','input_image')]),\n",
    "                           (priors_files, applyxformBM, [('brainmask','input_image')]),\n",
    "                           \n",
    "                           (applyxformBM, datasink, [('output_image','warped_brainmasks')]),\n",
    "                           (reg_to_template,datasink, [('warped_image','registered_T1')]),\n",
    "                           (applyxform, datasink, [('output_image','warped_tissues')])\n",
    "                          ])\n",
    "tissuepriors_flow.base_dir = workflow_dir\n",
    "tissuepriors_flow.write_graph(graph2use = 'flat')\n",
    "tissuepriors_flow.run('MultiProc', plugin_args={'n_procs': 4, 'memory_gb':10})\n",
    "\n",
    "# average the tissue maps\n",
    "merge_tissues = Merge(dimension='t')\n",
    "avg_tissues = MeanImage(dimension='T',output_datatype='double')\n",
    "from glob import glob\n",
    "from os import mkdir\n",
    "\n",
    "mkdir(proc_dir+'/tissue_priors')\n",
    "\n",
    "for a in range(0,6):\n",
    "    files = glob(proc_dir+'/warped_tissues/*/_applyxform{0}/tissue_class{1}_trans.nii.gz'.format(a,a+1))\n",
    "    merge_tissues.inputs.in_files = files\n",
    "    merge_tissues.inputs.merged_file = proc_dir+'/warped_tissues/merged_tissue{0}.nii.gz'.format(a)\n",
    "    merge_tissues.run()\n",
    "   \n",
    "    avg_tissues.inputs.in_file = proc_dir+'/warped_tissues/merged_tissue{0}.nii.gz'.format(a)\n",
    "    avg_tissues.inputs.out_file = proc_dir+'/tissue_priors/tissue{0}.nii.gz'.format(a)\n",
    "    avg_tissues.run()\n",
    "    \n",
    "files = glob(proc_dir+'/warped_brainmasks/*/brainmask_reoriented_thresh_trans.nii.gz')\n",
    "merge_tissues.inputs.in_files = files\n",
    "merge_tissues.inputs.merged_file = proc_dir+'/warped_tissues/merged_brainmasks.nii.gz'\n",
    "merge_tissues.run()\n",
    "\n",
    "avg_tissues.inputs.in_file = proc_dir+'/warped_tissues/merged_brainmasks.nii.gz'\n",
    "avg_tissues.inputs.out_file = proc_dir+'/tissue_priors/brainmask_prior.nii.gz'\n",
    "avg_tissues.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Cortical Thickness\n",
    "This section now takes all these items and calculates cortical thickness per subject. Last step before group analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
