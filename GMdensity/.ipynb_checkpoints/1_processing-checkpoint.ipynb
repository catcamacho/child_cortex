{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing T1w images to estimate Gray Matter Density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.spm.preprocess import VBMSegment, Segment\n",
    "from nipype.interfaces.ants import Atropos, Registration, ApplyTransforms, N4BiasFieldCorrection\n",
    "from nipype.interfaces.fsl import ApplyMask, BET\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "# Study specific variables\n",
    "study_home = '/moochie/Cat/Aggregate_anats/GMD_ML'\n",
    "\n",
    "sub_data_file = study_home + '/doc/subjectinfo.csv'\n",
    "subject_info = read_csv(sub_data_file)\n",
    "subjects_list = subject_info['SubjectID'].tolist()\n",
    "#subjects_list = ['101']\n",
    "\n",
    "raw_data = study_home + '/raw'\n",
    "output_dir = study_home + '/proc'\n",
    "workflow_dir = study_home + '/workflows'\n",
    "\n",
    "sample_template = study_home + '/templates/lcbd_template_1mm.nii.gz'\n",
    "sample_template_brain = study_home + '/templates/lcbd_template_1mm_brain.nii.gz'\n",
    "sample_template_mask = study_home + '/templates/lcbd_template_1mm_mask.nii.gz'\n",
    "\n",
    "# temporary tissue priors\n",
    "warp_gm = study_home + '/templates/MNI_gray_warp.nii.gz'\n",
    "warp_wm = study_home + '/templates/MNI_white_warp.nii.gz'\n",
    "warp_csf = study_home + '/templates/MNI_csf_warp.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list)]\n",
    "\n",
    "substitutions = [('_subjid_', '')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=output_dir,\n",
    "                         container=output_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-correct and segment subject images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the appropriate file to segment\n",
    "segmenttemplate = {'anat': raw_data + '/{subjid}/mprage.nii.gz'}\n",
    "segmentfiles = Node(SelectFiles(segmenttemplate), name='segmentfiles')\n",
    "\n",
    "# N4 bias correction\n",
    "biascorrect = Node(N4BiasFieldCorrection(save_bias=True),name='biascorrect')\n",
    "\n",
    "# Register to template brain\n",
    "reg_temp1 = Node(Registration(fixed_image=sample_template,\n",
    "                              args='--float',\n",
    "                              collapse_output_transforms=True,\n",
    "                              initial_moving_transform_com=True,\n",
    "                              num_threads=1,\n",
    "                              output_inverse_warped_image=True,\n",
    "                              output_warped_image=True,\n",
    "                              sigma_units=['vox']*2,\n",
    "                              transforms=['Rigid', 'Affine'],\n",
    "                              terminal_output='file',\n",
    "                              winsorize_lower_quantile=0.005,\n",
    "                              winsorize_upper_quantile=0.995,\n",
    "                              convergence_threshold=[1e-06],\n",
    "                              convergence_window_size=[10],\n",
    "                              metric=['Mattes', 'Mattes'],\n",
    "                              metric_weight=[1.0]*2,\n",
    "                              number_of_iterations=[[100, 75, 50],\n",
    "                                                    [100, 75, 50]],\n",
    "                              radius_or_number_of_bins=[32, 32],\n",
    "                              sampling_percentage=[0.25, 0.25],\n",
    "                              sampling_strategy=['Regular',\n",
    "                                                 'Regular'],\n",
    "                              shrink_factors=[[4, 2, 1]]*2,\n",
    "                              smoothing_sigmas=[[2, 1, 0]]*2,\n",
    "                              transform_parameters=[(0.1,),\n",
    "                                                    (0.1,)],\n",
    "                              use_histogram_matching=False,\n",
    "                              write_composite_transform=True),\n",
    "                 name='reg_temp1')\n",
    "\n",
    "# Skullstripping\n",
    "#skullstrip = Node(ApplyMask(mask_file=sample_template_mask),name='skullstrip')\n",
    "skullstrip = Node(BET(),name='skullstrip')\n",
    "\n",
    "# Register to skullstripped brain\n",
    "reg_temp2 = Node(Registration(fixed_image=sample_template_brain,\n",
    "                              args='--float',\n",
    "                              collapse_output_transforms=True,\n",
    "                              initial_moving_transform_com=True,\n",
    "                              num_threads=1,\n",
    "                              output_inverse_warped_image=True,\n",
    "                              output_warped_image=True,\n",
    "                              sigma_units=['vox']*2,\n",
    "                              transforms=['Affine', 'SyN'],\n",
    "                              terminal_output='file',\n",
    "                              winsorize_lower_quantile=0.005,\n",
    "                              winsorize_upper_quantile=0.995,\n",
    "                              convergence_threshold=[1e-06],\n",
    "                              convergence_window_size=[10],\n",
    "                              metric=['Mattes', 'Mattes'],\n",
    "                              metric_weight=[1.0]*2,\n",
    "                              number_of_iterations=[[100, 75, 50],\n",
    "                                                    [100, 75, 50]],\n",
    "                              radius_or_number_of_bins=[32, 32],\n",
    "                              sampling_percentage=[0.25, 0.25],\n",
    "                              sampling_strategy=['Regular',\n",
    "                                                 'Regular'],\n",
    "                              shrink_factors=[[4, 2, 1]]*2,\n",
    "                              smoothing_sigmas=[[2, 1, 0]]*2,\n",
    "                              transform_parameters=[(0.1,),\n",
    "                                                    (0.1,)],\n",
    "                              use_histogram_matching=False,\n",
    "                              write_composite_transform=True),\n",
    "                 name='reg_temp2')\n",
    "\n",
    "# Atropos segmentation\n",
    "segment = Node(Atropos(initialization='Otsu',\n",
    "                       number_of_tissue_classes=3, \n",
    "                       mask_image=sample_template_mask, \n",
    "                       save_posteriors=True, n_iterations=10),name='segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segproc = Workflow(name='segproc')\n",
    "segproc.connect([(infosource, segmentfiles,[('subjid','subjid')]), \n",
    "                 (segmentfiles,biascorrect,[('anat','input_image')]),\n",
    "                 (biascorrect,reg_temp1,[('output_image','moving_image')]),\n",
    "                 (reg_temp1, skullstrip, [('warped_image','in_file')]),\n",
    "                 (skullstrip, reg_temp2, [('out_file','moving_image')]), \n",
    "                 (reg_temp2, segment, [('warped_image','intensity_images')]),\n",
    "                 \n",
    "                 (reg_temp1, datasink, [('composite_transform','reg1_composite_transform'), \n",
    "                                        ('inverse_composite_transform','reg1_inverse_composite_transform'),\n",
    "                                        ('warped_image','reg1_warped_anat')]),\n",
    "                 (reg_temp2, datasink, [('composite_transform','reg2_composite_transform'),\n",
    "                                        ('inverse_composite_transform','reg2_inverse_composite_transform'),\n",
    "                                        ('warped_image','reg2_warped_anat')]),\n",
    "                 (segment, datasink, [('classified_image','hard_tissue_files'),('posteriors','soft_tissue_files')])\n",
    "                 \n",
    "                ])\n",
    "segproc.base_dir = workflow_dir\n",
    "segproc.write_graph(graph2use='flat')\n",
    "segproc.run('MultiProc', plugin_args={'n_procs': 4,'memory_gb':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
