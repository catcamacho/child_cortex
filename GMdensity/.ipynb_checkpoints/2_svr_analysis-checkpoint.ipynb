{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Gray Matter Markers of Irritability: a machine learning approach\n",
    "This notebook is designed to analyze previously processed gray matter density volumes using support vector regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>final_incl</th>\n",
       "      <th>Age_yrs</th>\n",
       "      <th>male</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>anger_frustration</th>\n",
       "      <th>...</th>\n",
       "      <th>shyness</th>\n",
       "      <th>smiling_laughter</th>\n",
       "      <th>MAP_Temper_Loss</th>\n",
       "      <th>MAP_Noncompliance</th>\n",
       "      <th>MAP_General_Aggression</th>\n",
       "      <th>MAP_Low_Concern</th>\n",
       "      <th>factor1</th>\n",
       "      <th>factor2</th>\n",
       "      <th>factor3</th>\n",
       "      <th>factor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.356557</td>\n",
       "      <td>0.658654</td>\n",
       "      <td>7.668843</td>\n",
       "      <td>0.504098</td>\n",
       "      <td>1.475894e+06</td>\n",
       "      <td>4.647537</td>\n",
       "      <td>4.122960</td>\n",
       "      <td>...</td>\n",
       "      <td>3.500356</td>\n",
       "      <td>5.453804</td>\n",
       "      <td>18.270408</td>\n",
       "      <td>4.019624</td>\n",
       "      <td>2.686327</td>\n",
       "      <td>2.973923</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>-0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455150</td>\n",
       "      <td>0.359408</td>\n",
       "      <td>0.401437</td>\n",
       "      <td>0.479967</td>\n",
       "      <td>0.475305</td>\n",
       "      <td>1.898534</td>\n",
       "      <td>0.501011</td>\n",
       "      <td>1.513949e+05</td>\n",
       "      <td>0.962907</td>\n",
       "      <td>1.413879</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161658</td>\n",
       "      <td>0.803623</td>\n",
       "      <td>17.634562</td>\n",
       "      <td>3.667544</td>\n",
       "      <td>3.097868</td>\n",
       "      <td>3.244351</td>\n",
       "      <td>1.030382</td>\n",
       "      <td>1.030799</td>\n",
       "      <td>0.984087</td>\n",
       "      <td>1.013322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.041068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142335e+06</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.693549</td>\n",
       "      <td>-2.172602</td>\n",
       "      <td>-2.771566</td>\n",
       "      <td>-2.480574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.323751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.372586e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.129870</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.777663</td>\n",
       "      <td>-0.777866</td>\n",
       "      <td>-0.622771</td>\n",
       "      <td>-0.778930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.374401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.477442e+06</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.882727</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.087539</td>\n",
       "      <td>-0.035900</td>\n",
       "      <td>0.121852</td>\n",
       "      <td>-0.082322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.778234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581896e+06</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>6.305195</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.684327</td>\n",
       "      <td>0.718004</td>\n",
       "      <td>0.805549</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.791239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.975068e+06</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>15.429091</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>15.111111</td>\n",
       "      <td>2.430133</td>\n",
       "      <td>2.286809</td>\n",
       "      <td>2.220284</td>\n",
       "      <td>2.453621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             seq1        seq2        seq3        seq4  final_incl     Age_yrs  \\\n",
       "count  244.000000  244.000000  244.000000  244.000000  208.000000  244.000000   \n",
       "mean     0.290984    0.151639    0.200820    0.356557    0.658654    7.668843   \n",
       "std      0.455150    0.359408    0.401437    0.479967    0.475305    1.898534   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    4.041068   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    6.323751   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    1.000000    7.374401   \n",
       "75%      1.000000    0.000000    0.000000    1.000000    1.000000    8.778234   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   12.791239   \n",
       "\n",
       "             male          eTIV  activity_level  anger_frustration  \\\n",
       "count  244.000000  2.300000e+02      206.000000         206.000000   \n",
       "mean     0.504098  1.475894e+06        4.647537           4.122960   \n",
       "std      0.501011  1.513949e+05        0.962907           1.413879   \n",
       "min      0.000000  1.142335e+06        2.142857           1.000000   \n",
       "25%      0.000000  1.372586e+06        4.000000           3.166667   \n",
       "50%      1.000000  1.477442e+06        4.714286           4.083333   \n",
       "75%      1.000000  1.581896e+06        5.290000           5.166667   \n",
       "max      1.000000  1.975068e+06        6.714286           7.000000   \n",
       "\n",
       "          ...         shyness  smiling_laughter  MAP_Temper_Loss  \\\n",
       "count     ...      206.000000        184.000000       196.000000   \n",
       "mean      ...        3.500356          5.453804        18.270408   \n",
       "std       ...        1.161658          0.803623        17.634562   \n",
       "min       ...        1.000000          2.666667         0.000000   \n",
       "25%       ...        2.666667          5.000000         5.000000   \n",
       "50%       ...        3.666667          5.500000        13.000000   \n",
       "75%       ...        4.333333          6.000000        25.500000   \n",
       "max       ...        6.333333          7.000000        81.000000   \n",
       "\n",
       "       MAP_Noncompliance  MAP_General_Aggression  MAP_Low_Concern     factor1  \\\n",
       "count         196.000000              196.000000       196.000000  184.000000   \n",
       "mean            4.019624                2.686327         2.973923   -0.008084   \n",
       "std             3.667544                3.097868         3.244351    1.030382   \n",
       "min             0.000000                0.000000         0.000000   -2.693549   \n",
       "25%             1.129870                0.320000         0.444444   -0.777663   \n",
       "50%             2.882727                1.760000         2.000000   -0.087539   \n",
       "75%             6.305195                3.720000         4.000000    0.684327   \n",
       "max            15.429091               13.600000        15.111111    2.430133   \n",
       "\n",
       "          factor2     factor3     factor4  \n",
       "count  184.000000  184.000000  184.000000  \n",
       "mean     0.011493    0.022467   -0.004770  \n",
       "std      1.030799    0.984087    1.013322  \n",
       "min     -2.172602   -2.771566   -2.480574  \n",
       "25%     -0.777866   -0.622771   -0.778930  \n",
       "50%     -0.035900    0.121852   -0.082322  \n",
       "75%      0.718004    0.805549    0.671329  \n",
       "max      2.286809    2.220284    2.453621  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.spm.preprocess import VBMSegment, Segment\n",
    "from nipype.interfaces.ants import Atropos, Registration, ApplyTransforms, N4BiasFieldCorrection\n",
    "from nipype.interfaces.fsl import ApplyMask, BET\n",
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "# Study specific variables\n",
    "study_home = '/moochie/user_data/CamachoCat/Aggregate_anats/GMD_ML'\n",
    "\n",
    "sub_data_file = study_home + '/doc/subject_info.csv'\n",
    "subject_info = read_csv(sub_data_file, index_col=0)\n",
    "subjects_list = subject_info['freesurferID'].tolist()\n",
    "\n",
    "preproc_dir = study_home + '/proc'\n",
    "output_dir = study_home + '/ml_trainingset'\n",
    "\n",
    "sample_template = study_home + '/templates/lcbd_template_1mm.nii.gz'\n",
    "sample_template_brain = study_home + '/templates/lcbd_template_1mm_brain.nii.gz'\n",
    "sample_template_mask = study_home + '/templates/lcbd_template_1mm_mask.nii.gz'\n",
    "\n",
    "subject_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(context='paper',style='white')\n",
    "#for variable in ['Age_yrs', 'MAP_Temper_Loss','MAP_Noncompliance','MAP_General_Aggression','MAP_Low_Concern']:\n",
    "#    plt.figure()\n",
    "#    sns.distplot(subject_info[variable],hist=True,kde=False,bins=30, color='#171C43', hist_kws={'edgecolor':'black'})\n",
    "    #plt.savefig(variable+'_hist.svg')\n",
    "    \n",
    "for variable in ['MAP_Temper_Loss','MAP_Noncompliance','MAP_General_Aggression','MAP_Low_Concern']:\n",
    "    plt.figure()\n",
    "    a = sns.jointplot(subject_info['Age_yrs'],subject_info[variable],\n",
    "                      marginal_kws={'kde':False,'bins':30})\n",
    "    a.annotate(stats.pearsonr,fontsize=12)\n",
    "    #plt.savefig(variable+'_age_corr.svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>final_incl</th>\n",
       "      <th>Age_yrs</th>\n",
       "      <th>male</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>anger_frustration</th>\n",
       "      <th>...</th>\n",
       "      <th>MAP_Low_Concern</th>\n",
       "      <th>factor1</th>\n",
       "      <th>factor2</th>\n",
       "      <th>factor3</th>\n",
       "      <th>factor4</th>\n",
       "      <th>temploss_yj</th>\n",
       "      <th>noncomp_yj</th>\n",
       "      <th>genagg_yj</th>\n",
       "      <th>lowcon_yj</th>\n",
       "      <th>age_cent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>1.960000e+02</td>\n",
       "      <td>1.960000e+02</td>\n",
       "      <td>1.960000e+02</td>\n",
       "      <td>1.960000e+02</td>\n",
       "      <td>2.440000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.356557</td>\n",
       "      <td>0.658654</td>\n",
       "      <td>7.668843</td>\n",
       "      <td>0.504098</td>\n",
       "      <td>1.475894e+06</td>\n",
       "      <td>4.647537</td>\n",
       "      <td>4.122960</td>\n",
       "      <td>...</td>\n",
       "      <td>2.973923</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>-0.004770</td>\n",
       "      <td>9.063045e-18</td>\n",
       "      <td>1.993870e-16</td>\n",
       "      <td>-3.172066e-16</td>\n",
       "      <td>-1.132881e-16</td>\n",
       "      <td>5.824121e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455150</td>\n",
       "      <td>0.359408</td>\n",
       "      <td>0.401437</td>\n",
       "      <td>0.479967</td>\n",
       "      <td>0.475305</td>\n",
       "      <td>1.898534</td>\n",
       "      <td>0.501011</td>\n",
       "      <td>1.513949e+05</td>\n",
       "      <td>0.962907</td>\n",
       "      <td>1.413879</td>\n",
       "      <td>...</td>\n",
       "      <td>3.244351</td>\n",
       "      <td>1.030382</td>\n",
       "      <td>1.030799</td>\n",
       "      <td>0.984087</td>\n",
       "      <td>1.013322</td>\n",
       "      <td>1.002561e+00</td>\n",
       "      <td>1.002561e+00</td>\n",
       "      <td>1.002561e+00</td>\n",
       "      <td>1.002561e+00</td>\n",
       "      <td>1.002056e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.041068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142335e+06</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.693549</td>\n",
       "      <td>-2.172602</td>\n",
       "      <td>-2.771566</td>\n",
       "      <td>-2.480574</td>\n",
       "      <td>-1.980704e+00</td>\n",
       "      <td>-1.802264e+00</td>\n",
       "      <td>-1.399991e+00</td>\n",
       "      <td>-1.336606e+00</td>\n",
       "      <td>-1.914758e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.323751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.372586e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.777663</td>\n",
       "      <td>-0.777866</td>\n",
       "      <td>-0.622771</td>\n",
       "      <td>-0.778930</td>\n",
       "      <td>-7.328741e-01</td>\n",
       "      <td>-7.853649e-01</td>\n",
       "      <td>-9.571042e-01</td>\n",
       "      <td>-8.457283e-01</td>\n",
       "      <td>-7.099464e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.374401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.477442e+06</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.087539</td>\n",
       "      <td>-0.035900</td>\n",
       "      <td>0.121852</td>\n",
       "      <td>-0.082322</td>\n",
       "      <td>3.652227e-02</td>\n",
       "      <td>1.841654e-02</td>\n",
       "      <td>9.826226e-02</td>\n",
       "      <td>8.370074e-02</td>\n",
       "      <td>-1.554081e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.778234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581896e+06</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.684327</td>\n",
       "      <td>0.718004</td>\n",
       "      <td>0.805549</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>7.100848e-01</td>\n",
       "      <td>8.606560e-01</td>\n",
       "      <td>7.667842e-01</td>\n",
       "      <td>6.984587e-01</td>\n",
       "      <td>5.855417e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.791239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.975068e+06</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.111111</td>\n",
       "      <td>2.430133</td>\n",
       "      <td>2.286809</td>\n",
       "      <td>2.220284</td>\n",
       "      <td>2.453621</td>\n",
       "      <td>2.142143e+00</td>\n",
       "      <td>1.935011e+00</td>\n",
       "      <td>1.944626e+00</td>\n",
       "      <td>2.005997e+00</td>\n",
       "      <td>2.703625e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             seq1        seq2        seq3        seq4  final_incl     Age_yrs  \\\n",
       "count  244.000000  244.000000  244.000000  244.000000  208.000000  244.000000   \n",
       "mean     0.290984    0.151639    0.200820    0.356557    0.658654    7.668843   \n",
       "std      0.455150    0.359408    0.401437    0.479967    0.475305    1.898534   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    4.041068   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    6.323751   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    1.000000    7.374401   \n",
       "75%      1.000000    0.000000    0.000000    1.000000    1.000000    8.778234   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   12.791239   \n",
       "\n",
       "             male          eTIV  activity_level  anger_frustration  \\\n",
       "count  244.000000  2.300000e+02      206.000000         206.000000   \n",
       "mean     0.504098  1.475894e+06        4.647537           4.122960   \n",
       "std      0.501011  1.513949e+05        0.962907           1.413879   \n",
       "min      0.000000  1.142335e+06        2.142857           1.000000   \n",
       "25%      0.000000  1.372586e+06        4.000000           3.166667   \n",
       "50%      1.000000  1.477442e+06        4.714286           4.083333   \n",
       "75%      1.000000  1.581896e+06        5.290000           5.166667   \n",
       "max      1.000000  1.975068e+06        6.714286           7.000000   \n",
       "\n",
       "           ...       MAP_Low_Concern     factor1     factor2     factor3  \\\n",
       "count      ...            196.000000  184.000000  184.000000  184.000000   \n",
       "mean       ...              2.973923   -0.008084    0.011493    0.022467   \n",
       "std        ...              3.244351    1.030382    1.030799    0.984087   \n",
       "min        ...              0.000000   -2.693549   -2.172602   -2.771566   \n",
       "25%        ...              0.444444   -0.777663   -0.777866   -0.622771   \n",
       "50%        ...              2.000000   -0.087539   -0.035900    0.121852   \n",
       "75%        ...              4.000000    0.684327    0.718004    0.805549   \n",
       "max        ...             15.111111    2.430133    2.286809    2.220284   \n",
       "\n",
       "          factor4   temploss_yj    noncomp_yj     genagg_yj     lowcon_yj  \\\n",
       "count  184.000000  1.960000e+02  1.960000e+02  1.960000e+02  1.960000e+02   \n",
       "mean    -0.004770  9.063045e-18  1.993870e-16 -3.172066e-16 -1.132881e-16   \n",
       "std      1.013322  1.002561e+00  1.002561e+00  1.002561e+00  1.002561e+00   \n",
       "min     -2.480574 -1.980704e+00 -1.802264e+00 -1.399991e+00 -1.336606e+00   \n",
       "25%     -0.778930 -7.328741e-01 -7.853649e-01 -9.571042e-01 -8.457283e-01   \n",
       "50%     -0.082322  3.652227e-02  1.841654e-02  9.826226e-02  8.370074e-02   \n",
       "75%      0.671329  7.100848e-01  8.606560e-01  7.667842e-01  6.984587e-01   \n",
       "max      2.453621  2.142143e+00  1.935011e+00  1.944626e+00  2.005997e+00   \n",
       "\n",
       "           age_cent  \n",
       "count  2.440000e+02  \n",
       "mean   5.824121e-16  \n",
       "std    1.002056e+00  \n",
       "min   -1.914758e+00  \n",
       "25%   -7.099464e-01  \n",
       "50%   -1.554081e-01  \n",
       "75%    5.855417e-01  \n",
       "max    2.703625e+00  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from numpy import squeeze\n",
    "\n",
    "## Create a conditions list for the feature set\n",
    "age_labels = subject_info[['Age_yrs']].copy()\n",
    "age_labels = age_labels.values\n",
    "irr_labels = subject_info[['MAP_Temper_Loss','MAP_Noncompliance','MAP_General_Aggression','MAP_Low_Concern']].copy()\n",
    "irr_labels = irr_labels.values\n",
    "\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "scaler.fit(age_labels)\n",
    "sd_agedata = scaler.transform(age_labels)\n",
    "\n",
    "pt = PowerTransformer()\n",
    "pt.fit(irr_labels)\n",
    "pt_irritability = pt.transform(irr_labels)\n",
    "pt_irritability = squeeze(pt_irritability)\n",
    "\n",
    "subject_info = subject_info.merge(DataFrame(pt_irritability,\n",
    "                                            columns=['temploss_yj','noncomp_yj','genagg_yj','lowcon_yj'],\n",
    "                                            index=subject_info.index),left_index=True, right_index=True)\n",
    "subject_info['age_cent'] = sd_agedata\n",
    "\n",
    "#subject_info.to_csv(output_dir + '/featureset_key.csv')\n",
    "subject_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.scatterplot(x='MAP_Temper_Loss',y='temploss_yj',data=subject_info)\n",
    "plt.figure()\n",
    "plt.hist(subject_info['temploss_yj'][np.isfinite(subject_info['temploss_yj'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate all the parameter estimates from preproc to create a feature set\n",
    "from nipype.interfaces.fsl.utils import Merge\n",
    "\n",
    "gm_template = preproc_dir + '/final_gmd/{0}/final_smooth_gm.nii.gz'\n",
    "gm_files = []\n",
    "for sub in subjects_list:\n",
    "    gm_files.append(gm_template.format(sub))\n",
    "gmd_feature_data = output_dir + '/gmd_combined.nii.gz'\n",
    "#print(gm_files)\n",
    "merge = Merge()\n",
    "merge.inputs.in_files = gm_files\n",
    "merge.inputs.dimension = 't'\n",
    "merge.inputs.merged_file = gmd_feature_data\n",
    "#merge.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import GLM, Merge\n",
    "from os.path import abspath\n",
    "from subprocess import check_call\n",
    "\n",
    "usable_subs = subject_info[subject_info['final_incl']==1]\n",
    "subjects_list = usable_subs['freesurferID'].tolist()\n",
    "ages = usable_subs['age_cent'].tolist()\n",
    "male = usable_subs['male'].tolist()\n",
    "seq1 = usable_subs['seq1'].tolist()\n",
    "seq2 = usable_subs['seq2'].tolist()\n",
    "seq3 = usable_subs['seq3'].tolist()\n",
    "seq4 = usable_subs['seq4'].tolist()\n",
    "eTIV = usable_subs['eTIV'].tolist()\n",
    "\n",
    "final_data_list = []\n",
    "text_file = open('temp_text.txt','w')\n",
    "\n",
    "for a in range(0,len(subjects_list)):\n",
    "    file = preproc_dir + '/final_gmd/{0}/final_smooth_gm.nii.gz'.format(subjects_list[a])\n",
    "    final_data_list.append(file)\n",
    "    text_file.write('{0} {1} {2} {3} {4} {5}\\n'.format(male[a], seq1[a], seq2[a], seq3[a],seq4[a], eTIV[a]))\n",
    "    \n",
    "text_file.close()\n",
    "\n",
    "file = abspath('temp_text.txt')\n",
    "check_call(['Text2Vest',file,'design.mat'])\n",
    "design_file = abspath('design.mat')\n",
    "\n",
    "me=Merge()\n",
    "me.inputs.dimension='t'\n",
    "me.inputs.in_files=final_data_list\n",
    "me.inputs.merged_file='data_merged.nii.gz'\n",
    "me.run()\n",
    "merged_gmd = abspath('data_merged.nii.gz')\n",
    "\n",
    "glm = GLM()\n",
    "glm.inputs.in_file = merged_gmd\n",
    "glm.inputs.design = design_file\n",
    "glm.inputs.mask = sample_template_mask\n",
    "glm.inputs.out_res_name = 'data_resids_noage.nii.gz'\n",
    "glm.run()\n",
    "\n",
    "final_data = abspath('data_resids_noage.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "analysis = 'Age'\n",
    "masker = NiftiMasker(mask_img=sample_template_mask,standardize=True, \n",
    "                     memory='nilearn_cache', memory_level=1)\n",
    "X = masker.fit_transform(gmd_feature_data)\n",
    "\n",
    "if analysis == 'Age':\n",
    "    mask = subject_info['final_incl']==1\n",
    "    labels = subject_info['age_cent'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X=X[mask]\n",
    "elif analysis == 'Temper_Loss':\n",
    "    mask = (subject_info['MAP_Temper_Loss']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['temploss_yj'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'Noncompliance':\n",
    "    mask = (subject_info['MAP_Noncompliance']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['noncomp_yj'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'General_Aggression':\n",
    "    mask = (subject_info['MAP_General_Aggression']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['genagg_yj'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'Low_Concern':\n",
    "    mask = (subject_info['MAP_Low_Concern']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['lowcon_yj'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'factor1':\n",
    "    mask = (subject_info['smiling_laughter']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['factor1'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'factor2':\n",
    "    mask = (subject_info['smiling_laughter']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['factor2'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'factor3':\n",
    "    mask = (subject_info['smiling_laughter']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['factor3'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "elif analysis == 'factor4':\n",
    "    mask = (subject_info['smiling_laughter']>=0) & (subject_info['final_incl']==1)\n",
    "    labels = subject_info['factor4'][mask]\n",
    "    groups = subject_info['freesurferID'][mask]\n",
    "    X = X[mask]\n",
    "    \n",
    "analysis= analysis\n",
    "results_file = open(output_dir + '/results_' + analysis + '.txt','w')\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the support vector classification\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn.feature_selection import f_regression, SelectPercentile\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# Set up the regression\n",
    "svr = SVR(kernel='linear', C=1)\n",
    "\n",
    "feature_selection = SelectPercentile(f_regression, percentile=5)\n",
    "fs_svr = Pipeline([('feat_select', feature_selection), ('svr', svr)])\n",
    "\n",
    "# Run the regression\n",
    "fs_svr.fit(X, labels)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneGroupOut, RepeatedKFold\n",
    "\n",
    "cv = LeaveOneGroupOut()\n",
    "#cv = RepeatedKFold(n_splits=10,n_repeats=10)\n",
    "y_pred = cross_val_predict(fs_svr, X, y=labels, n_jobs=10,groups=groups,cv=cv)\n",
    "\n",
    "# save weights\n",
    "coef = svr.coef_\n",
    "coef = feature_selection.inverse_transform(coef)\n",
    "coef_image = masker.inverse_transform(coef)\n",
    "coef_image.to_filename(output_dir + '/svrweights_' + analysis + '.nii.gz')\n",
    "\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_val, p_val, stderr = linregress(labels, y_pred) \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(labels, y_pred)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "spear_r, spear_p = spearmanr(labels, y_pred)\n",
    "\n",
    "print(\"prediction accuracy: %.4f / p-value: %f / MSE: %f // Spearman: %f / p-value: %f\" % (r_val, p_val, mse, spear_r, spear_p))\n",
    "\n",
    "svr_results=DataFrame()\n",
    "svr_results['labels']=labels\n",
    "svr_results['y_pred']=Series(y_pred,index=labels.index)\n",
    "# plot the predicted versus actual values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='poster',style='white')\n",
    "sns.lmplot(x='labels', y='y_pred',ci=None,data=svr_results)\n",
    "plt.xlabel('Actual ' + analysis)\n",
    "plt.ylabel('Predicted ' + analysis)\n",
    "plt.savefig(output_dir + '/scatter_pred_actual_' + analysis + '_poster.svg')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "results_file.write(\"Prediction accuracy r-value: %.4f / p-value: %f / MSE: %f // Spearman: %f / p-value: %f \\n\" % (r_val, p_val, mse, spear_r, spear_p))\n",
    "results_file.write('predicted: ' + str(y_pred) + '\\n')\n",
    "results_file.write('actual: ' + str(labels) + '\\n')\n",
    "\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "\n",
    "results_file = open(output_dir + '/perm_results_' + analysis + '.txt','w')\n",
    "\n",
    "score, permutation_scores, pvalue = permutation_test_score(fs_svr, X, labels, scoring='neg_mean_squared_error', \n",
    "                                                           cv=cv, n_permutations=500, n_jobs=20, groups=groups)\n",
    "savetxt(output_dir + '/permutation_scores_mse_' + analysis + '.txt', permutation_scores)\n",
    "\n",
    "# Save a figure of the permutation scores\n",
    "plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "         edgecolor='black')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "         label='Mean Squared Error (pvalue %f)' % pvalue)\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.savefig(output_dir + '/permutation_plot_mse_' + analysis + '.svg', transparent=True)\n",
    "plt.close()\n",
    "\n",
    "# save final pval/classifier score\n",
    "results_file.write('MSE score %s (pvalue : %s) \\n' % (score, pvalue))\n",
    "\n",
    "## Perform permutation testing to get a p-value for r-squared\n",
    "score, permutation_scores, pvalue = permutation_test_score(fs_svr, X, labels, scoring='r2', \n",
    "                                                           cv=cv, n_permutations=500, n_jobs=20, groups=groups)\n",
    "savetxt(output_dir + '/permutation_scores_r2_' + analysis + '.txt', permutation_scores)\n",
    "\n",
    "# Save a figure of the permutation scores\n",
    "plt.hist(permutation_scores, 20, label='Permutation scores',\n",
    "         edgecolor='black')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "         label='R-squared (pvalue %f)' % pvalue)\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.savefig(output_dir + '/permutation_plot_r2_' + analysis + '.svg', transparent=True)\n",
    "plt.close()\n",
    "\n",
    "# save final pval/classifier score\n",
    "results_file.write('R square: %s (pvalue : %s) \\n' % (score, pvalue))\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "analysis = 'sequence_LOSO_6_10'\n",
    "masker = NiftiMasker(mask_img=sample_template_mask,standardize=True, \n",
    "                     memory='nilearn_cache', memory_level=1)\n",
    "X = masker.fit_transform(gmd_feature_data)\n",
    "mask=(conditions.age_yrs<=10) & (conditions.age_yrs>=6)\n",
    "\n",
    "if analysis == 'sequence_LOSO':\n",
    "    labels = conditions['sequence']\n",
    "    groups = conditions['subject'] \n",
    "elif analysis == 'sequence_LOGO':\n",
    "    labels = conditions['sequence']\n",
    "    groups = conditions['sequence'] \n",
    "elif analysis == 'sequence_LOSO_6_10':\n",
    "    labels = conditions['sequence'][mask]\n",
    "    groups = conditions['subject'][mask]\n",
    "    X=X[mask]\n",
    "\n",
    "    \n",
    "results_file = open(output_dir + '/results_' + analysis + '.txt','w')\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the support vector classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set up the support vector classifier\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# Select the features contributing to the model\n",
    "feature_selection = SelectPercentile(f_classif, percentile=5) #0.05/228453 voxels\n",
    "fs_svc = Pipeline([('feat_select', feature_selection), ('svc', svc)])\n",
    "\n",
    "# Run the classifier\n",
    "fs_svc.fit(X, labels)\n",
    "\n",
    "# Obtain prediction values via cross validation\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, cross_val_predict\n",
    "\n",
    "loso = LeaveOneGroupOut()\n",
    "cv_scores = cross_validate(fs_svc, X, y=labels, n_jobs=20, return_train_score=True,\n",
    "                           groups=groups, cv=loso, scoring='accuracy')\n",
    "y_pred = cross_val_predict(fs_svc, X, y=labels, n_jobs=20,groups=groups, cv=loso)\n",
    "\n",
    "## Save the SVM weights to a nifti\n",
    "coef = svc.coef_\n",
    "coef = feature_selection.inverse_transform(coef)\n",
    "weight_img = masker.inverse_transform(coef)\n",
    "weight_img.to_filename(output_dir + '/svmweights_'+ analysis +'.nii.gz')\n",
    "\n",
    "## Calculate performance metrics\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "classification_accuracy = cv_scores['test_score'].mean()\n",
    "chance = 1. / len(labels.unique())\n",
    "print(\"Classification accuracy: %.4f / Chance level: %f\" % \n",
    "      (classification_accuracy, chance))\n",
    "\n",
    "for label in labels.unique():\n",
    "    sensitivity = recall_score(labels,y_pred,labels=[label],average='weighted')\n",
    "    precision = precision_score(labels,y_pred,labels=[label],average='weighted')\n",
    "\n",
    "    results_file.write(\"%s: classification accuracy: %.4f \\n chance level: %f \\n sensitivity: %f \\n precision: %f \\n\" % \n",
    "    (label, classification_accuracy, chance, sensitivity, precision))\n",
    "\n",
    "# compute and display a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import set_printoptions\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cnf_matrix = confusion_matrix(labels, y_pred)\n",
    "set_printoptions(precision=2)\n",
    "classes = labels.unique()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    from numpy import arange\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size=16)\n",
    "    plt.yticks(tick_marks, classes, size=16)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j],  'd'),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black', size=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', size=16)\n",
    "    plt.xlabel('Predicted label', size=16)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes)\n",
    "plt.savefig(output_dir + '/confusion_matrix_' + analysis + '.svg', transparent=True)\n",
    "plt.close()\n",
    "\n",
    "results_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
